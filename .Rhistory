# tpp_pp22 <- tpp_pp22 %>%
#   mutate(winner = ifelse(ALP_Percent >= 50, "ALP", "LNP"))
#
# head(tpp_pp22, n=10)
tpp_pp <- twoparty_pollingbooth_download()
tpp_pp22 <- tpp_pp %>% dplyr::filter(year == 2022)
head(tpp_pp22)
# nat_data22 <- nat_data_download(2022)
# nat_map22 <- nat_map_download(2022)
#
# # Find winner
# tpp_pp22 <- tpp_pp22 %>%
#   mutate(winner = ifelse(ALP_Percent >= 50, "ALP", "LNP"))
#
# head(tpp_pp22, n=10)
tpp_pp <- twoparty_pollingbooth_download()
tail(tpp_pp)
tpp_pp22 <- tpp_pp %>% dplyr::filter(year == 2022)
head(tpp_pp22)
# nat_data22 <- nat_data_download(2022)
# nat_map22 <- nat_map_download(2022)
#
# # Find winner
# tpp_pp22 <- tpp_pp22 %>%
#   mutate(winner = ifelse(ALP_Percent >= 50, "ALP", "LNP"))
#
# head(tpp_pp22, n=10)
tpp_pp <- twoparty_pollingbooth_download()
tail(tpp_pp)
# tpp_pp22 <- tpp_pp %>% dplyr::filter(year == 2022)
#
# head(tpp_pp22)
# nat_data22 <- nat_data_download(2022)
# nat_map22 <- nat_map_download(2022)
#
# # Find winner
# tpp_pp22 <- tpp_pp22 %>%
#   mutate(winner = ifelse(ALP_Percent >= 50, "ALP", "LNP"))
#
# head(tpp_pp22, n=10)
tpp_pp <- twoparty_pollingbooth_download()
tpp_pp16 <- tpp_pp %>% filter(year == 2016)
# Find winner
tpp_pp16 <- tpp_pp16 %>%
mutate(winner = ifelse(ALP_Percent >= 50, "ALP", "LNP"))
ggplot(data=nat_data16, aes(map_id=id)) +
geom_map(map=nat_map16, fill="grey90", colour="white") +
geom_point(data=tpp_pp16, aes(x=Longitude, y=Latitude, colour=winner), size=1, alpha=0.3, inherit.aes=FALSE) +
scale_color_manual("Party", values=c("LNP"="#80b1d3", "ALP"="#fb8072")) +
xlim(c(112,157)) + ylim(c(-44,-11)) +
theme_map() + coord_equal() + theme(legend.position="bottom")
library(ggparliament)  # If working with parliamentary data
library(tidyverse)      # Includes dplyr, ggplot2, tidyr, purrr, and more
library(ggthemes)
library(readxl)         # Reading Excel files
library(sf)             # Spatial data handling
library(DT)
library(eechidna)
library(absmapsdata)
# Find the list of 2016 booth locations
booths <- read_csv("http://results.aec.gov.au/20499/Website/Downloads/GeneralPollingPlacesDownload-20499.csv", skip=1)
head(booths, n=10)
tpp_pp <- twoparty_pollingbooth_download()
tpp_pp16 <- tpp_pp %>% filter(year == 2016)
# Find winner
tpp_pp16 <- tpp_pp16 %>%
mutate(winner = ifelse(ALP_Percent >= 50, "ALP", "LNP"))
ggplot(data=nat_data16, aes(map_id=id)) +
geom_map(map=nat_map16, fill="grey90", colour="white") +
geom_point(data=tpp_pp16, aes(x=Longitude, y=Latitude, colour=winner), size=1, alpha=0.3, inherit.aes=FALSE) +
scale_color_manual("Party", values=c("LNP"="#80b1d3", "ALP"="#fb8072")) +
xlim(c(112,157)) + ylim(c(-44,-11)) +
theme_map() + coord_equal() + theme(legend.position="bottom")
tcp_pp <- twocand_pollingbooth_download()
tcp_pp16 <- tcp_pp %>% filter(year == 2016)
# Find winner
tcp_pp_winners <- tcp_pp16 %>%
left_join(tcp_pp16 %>% dplyr::group_by(PollingPlace, DivisionNm) %>%                         summarise(TotalVotes = sum(OrdinaryVotes)),
by = c("PollingPlace", "DivisionNm")) %>%
filter(OrdinaryVotes/TotalVotes > 0.5)
# Plot
ggplot(data=nat_data16, aes(map_id=id)) +
geom_map(map=nat_map16, fill="grey90", colour="white") +
geom_point(data=tcp_pp_winners, aes(x=Longitude, y=Latitude, colour=PartyAb), size=1, alpha=0.6, inherit.aes=FALSE) +
scale_color_manual("Party", values=c("LNP"="#80b1d3", "ALP"="#fb8072", "GRN" = "#33a02c", "XEN" = "#beaed4", "ON" = "#fdc086", "KAP" = "#ffff99", "IND" = "grey25")) +
xlim(c(112,157)) + ylim(c(-44,-11)) +
theme_map() + coord_equal() + theme(legend.position="bottom")
nat_data16
tpp_pp <- twoparty_pollingbooth_download()
tpp_pp16 <- tpp_pp %>% filter(year == 2016)
nat_data16 <- nat_data_download(2016)
# Find winner
tpp_pp16 <- tpp_pp16 %>%
mutate(winner = ifelse(ALP_Percent >= 50, "ALP", "LNP"))
ggplot(data=nat_data16, aes(map_id=id)) +
geom_map(map=nat_map16, fill="grey90", colour="white") +
geom_point(data=tpp_pp16, aes(x=Longitude, y=Latitude, colour=winner), size=1, alpha=0.3, inherit.aes=FALSE) +
scale_color_manual("Party", values=c("LNP"="#80b1d3", "ALP"="#fb8072")) +
xlim(c(112,157)) + ylim(c(-44,-11)) +
theme_map() + coord_equal() + theme(legend.position="bottom")
nat_map16
tpp_pp <- twoparty_pollingbooth_download()
tpp_pp16 <- tpp_pp %>% filter(year == 2016)
nat_data16 <- nat_data_download(2016)
nat_map16 <- nat_map_download(2016)
# Find winner
tpp_pp16 <- tpp_pp16 %>%
mutate(winner = ifelse(ALP_Percent >= 50, "ALP", "LNP"))
ggplot(data=nat_data16, aes(map_id=id)) +
geom_map(map=nat_map16, fill="grey90", colour="white") +
geom_point(data=tpp_pp16, aes(x=Longitude, y=Latitude, colour=winner), size=1, alpha=0.3, inherit.aes=FALSE) +
scale_color_manual("Party", values=c("LNP"="#80b1d3", "ALP"="#fb8072")) +
xlim(c(112,157)) + ylim(c(-44,-11)) +
theme_map() + coord_equal() + theme(legend.position="bottom")
tcp_pp <- twocand_pollingbooth_download()
tcp_pp16 <- tcp_pp %>% filter(year == 2016)
nat_data16 <- nat_data_download(2016)
nat_map16 <- nat_map_download(2016)
# Find winner
tcp_pp_winners <- tcp_pp16 %>%
left_join(tcp_pp16 %>% dplyr::group_by(PollingPlace, DivisionNm) %>%                         summarise(TotalVotes = sum(OrdinaryVotes)),
by = c("PollingPlace", "DivisionNm")) %>%
filter(OrdinaryVotes/TotalVotes > 0.5)
# Plot
ggplot(data=nat_data16, aes(map_id=id)) +
geom_map(map=nat_map16, fill="grey90", colour="white") +
geom_point(data=tcp_pp_winners, aes(x=Longitude, y=Latitude, colour=PartyAb), size=1, alpha=0.6, inherit.aes=FALSE) +
scale_color_manual("Party", values=c("LNP"="#80b1d3", "ALP"="#fb8072", "GRN" = "#33a02c", "XEN" = "#beaed4", "ON" = "#fdc086", "KAP" = "#ffff99", "IND" = "grey25")) +
xlim(c(112,157)) + ylim(c(-44,-11)) +
theme_map() + coord_equal() + theme(legend.position="bottom")
#Loads the required required packages
pacman::p_load(ggmap,
tmaptools,
RCurl,
jsonlite,
tidyverse,
leaflet,
writexl,
readr,
readxl,
sf,
mapview,
rgdal)
#Read in spreadsheet
url <- 'https://raw.githubusercontent.com/charlescoverdale/bookdata/main/mobile-camera-locations-june-2022.csv'
#Note: We need to import as a csv rather than xlsx for url functionality
camera_address <- read.csv(url, header=TRUE)
#Fix the column labels
camera_address <- janitor::row_to_names(camera_address,1)
#Convert the suburb column to title case
camera_address$SUBURB <- str_to_title(camera_address$SUBURB)
#Concatenate the two fields into a single address field
camera_address$ADDRESS <- paste(camera_address$LOCATION,
camera_address$SUBURB,
sep=", ")
#Add in Australia to the address field just to idiot proof the df
camera_address$ADDRESS <- paste(camera_address$ADDRESS, ", Australia", sep="")
#Preview the data
head(camera_address)
# #Input the google API key
# register_google(key = "PASTE YOUR UNIQUE KEY HERE")
#
# #Run the geocode function from ggmap package
# camera_ggmap <- ggmap::geocode(location = camera_address$ADDRESS,
#                          output = "more",
#                          source = "google")
#
# #We'll bind the newly created address columns to the original df
# camera_ggmap <- cbind(camera_address, camera_ggmap)
#
# #Print the results
# head(camera_ggmap)
#
# #Write the data to a df
# readr::write_csv(camera_ggmap,"C:/Data/camera_geocoded.csv")
#Input the google API key
register_google(key = "PASTE YOUR UNIQUE KEY HERE")
#Run the geocode function from ggmap package
camera_ggmap <- ggmap::geocode(location = camera_address$ADDRESS,
output = "more",
source = "google")
url <- 'https://raw.githubusercontent.com/charlescoverdale/bookdata/main/camera_geocoded.csv'
#Note: We need to import as a csv rather than xlsx for url functionality
camera_ggmap <- read.csv(url, header=TRUE)
camera_geocoded <- camera_ggmap
#Rename df
camera_geocoded_clean <- camera_geocoded
#Rename the API generated address field
camera_geocoded_clean <- camera_geocoded_clean %>% rename(address_long=address)
#Select only the columns we need
camera_geocoded_clean <- camera_geocoded_clean %>%
select("LOCATION",
"SUBURB",
"ADDRESS",
"lon",
"lat",
"address_long"
)
#Make all the column names the same format
camera_geocoded_clean <- janitor::clean_names(camera_geocoded_clean)
#We still need to convert address_long to title case
camera_geocoded_clean$address_long <- str_to_title(camera_geocoded_clean$address_long)
#Convert data frame to sf object
camera_points <- sf::st_as_sf(x = camera_geocoded_clean,
coords = c("lon", "lat"),
crs = "+proj=longlat
+datum=WGS84
+ellps=WGS84
+towgs84=0,0,0")
#Plot an interactive map
mapview(camera_points)
#Write the points to a shapefile for use in QGIS
#sf::st_write(camera_points, "C:/Data/camera_points.shp")
camera_points$postcode <- str_sub(camera_points$address_long,
start= -16,
end= -12)
camera_points$postcode <- as.numeric(camera_points$postcode)
outliers <- camera_points %>% filter (postcode <3000 | postcode >= 4000)
print(outliers)
camera_points_vic <- camera_points %>% filter (postcode>"3000" & postcode<"4000")
#Plot an interactive map
mapview(camera_points_vic)
#Write the points to a shapefile for use in QGIS
#sf::st_write(camera_points_vic, "C:/Data/camera_points_vic.shp")
#Convert data frame to sf object
camera_points <- sf::st_as_sf(x = camera_geocoded_clean,
coords = c("lon", "lat"),
crs = "+proj=longlat
+datum=WGS84
+ellps=WGS84
+towgs84=0,0,0")
#Plot an interactive map
plot(camera_points)
#Convert data frame to sf object
camera_points <- sf::st_as_sf(x = camera_geocoded_clean,
coords = c("lon", "lat"),
crs = "+proj=longlat
+datum=WGS84
+ellps=WGS84
+towgs84=0,0,0")
#Plot an interactive map
mapview(camera_points)
camera_points
#Convert data frame to sf object
camera_points <- sf::st_as_sf(x = camera_geocoded_clean,
coords = c("lon", "lat"),
crs = "+proj=longlat
+datum=WGS84
+ellps=WGS84
+towgs84=0,0,0")
#Plot an interactive map
#mapview(camera_points)
# Plot points on the map
ggplot() +
geom_sf(data = australia, fill = "gray90", color = "black") +  # Base map
geom_sf(data = camera_points, aes(color = suburb), alpha = 0.7) +  # Plot points
labs(title = "Geocoded Locations in Australia",
subtitle = "Plotted using ggplot2 and sf",
color = "Suburb") +
theme_minimal()
#Convert data frame to sf object
camera_points <- sf::st_as_sf(x = camera_geocoded_clean,
coords = c("lon", "lat"),
crs = "+proj=longlat
+datum=WGS84
+ellps=WGS84
+towgs84=0,0,0")
#Plot an interactive map
#mapview(camera_points)
# Plot points on the map
ggplot() +
geom_sf(data = absmapsdata:state2021, fill = "gray90", color = "black") +  # Base map
geom_sf(data = camera_points, aes(color = suburb), alpha = 0.7) +  # Plot points
labs(title = "Geocoded Locations in Australia",
subtitle = "Plotted using ggplot2 and sf",
color = "Suburb") +
theme_minimal()
#Loads the required required packages
pacman::p_load(ggmap,
tmaptools,
RCurl,
jsonlite,
tidyverse,
leaflet,
writexl,
readr,
readxl,
sf,
mapview,
rgdal)
#Convert data frame to sf object
camera_points <- sf::st_as_sf(x = camera_geocoded_clean,
coords = c("lon", "lat"),
crs = "+proj=longlat
+datum=WGS84
+ellps=WGS84
+towgs84=0,0,0")
#Plot an interactive map
#mapview(camera_points)
# Plot points on the map
ggplot() +
geom_sf(data = absmapsdata::state2021, fill = "gray90", color = "black") +  # Base map
geom_sf(data = camera_points, aes(color = suburb), alpha = 0.7) +  # Plot points
labs(title = "Geocoded Locations in Australia",
subtitle = "Plotted using ggplot2 and sf",
color = "Suburb") +
theme_minimal()
#Create a dataframe with the lat and long
locations <- tibble::tribble(~place,
~lon,
~lat,
"Melbourne",
144.9631,
-37.8136)
#Run it through the osrm package
iso <- osrmIsochrone(loc = c(locations$lon,
locations$lat),
breaks = seq(from = 0,
to = 30,
by = 5),
res=50)
#Loads the required required packages
pacman::p_load(ggmap, tmaptools, RCurl, jsonlite, tidyverse, leaflet, writexl, readr, readxl, sf, mapview, rgdal, osrm)
#Create a dataframe with the lat and long
locations <- tibble::tribble(~place,
~lon,
~lat,
"Melbourne",
144.9631,
-37.8136)
#Run it through the osrm package
iso <- osrmIsochrone(loc = c(locations$lon,
locations$lat),
breaks = seq(from = 0,
to = 30,
by = 5),
res=50)
#iso@data$drive_times <- factor(paste(iso@data$min, "to", iso@data$max, "mins"))
#factpal <- colorFactor("RdYlBu", iso@data$drive_times)
leaflet() %>%
setView(mean(locations$lon), mean(locations$lat), zoom = 7) %>%
addProviderTiles("CartoDB.Positron", group="Greyscale") %>%
addMarkers(lng = locations$lon, locations$lat) %>%
addPolygons(fill=TRUE, stroke=TRUE, color = "black",
#fillColor = ~factpal(iso@data$drive_times),
weight=0.5, fillOpacity=0.2,
data = iso, #popup = iso@data$drive_times,
group = "Drive Time") #%>%
# Create a dataframe with the latitude and longitude
locations <- tibble::tribble(
~place,     ~lon,     ~lat,
"Melbourne", 144.9631, -37.8136
)
# Run it through the osrm package to calculate isochrones
iso <- osrmIsochrone(
loc = c(locations$lon, locations$lat),
breaks = seq(from = 0, to = 30, by = 5),
res = 50
)
# Create an interactive map
leaflet() %>%
setView(mean(locations$lon), mean(locations$lat), zoom = 7) %>%
addProviderTiles("CartoDB.Positron", group = "Greyscale") %>%
addMarkers(lng = locations$lon, lat = locations$lat) %>%
addPolygons(
fill = TRUE, stroke = TRUE, color = "black",
weight = 0.5, fillOpacity = 0.2,
data = iso,
group = "Drive Time"
)
#Convert data frame to sf object
camera_points <- sf::st_as_sf(x = camera_geocoded_clean,
coords = c("lon", "lat"),
crs = "+proj=longlat
+datum=WGS84
+ellps=WGS84
+towgs84=0,0,0")
#Plot an interactive map
mapview(camera_points)
#Read in spreadsheet
url <- 'https://raw.githubusercontent.com/charlescoverdale/bookdata/main/mobile-camera-locations-june-2022.csv'
#Note: We need to import as a csv rather than xlsx for url functionality
camera_address <- read.csv(url, header=TRUE)
#Fix the column labels
camera_address <- janitor::row_to_names(camera_address,1)
#Convert the suburb column to title case
camera_address$SUBURB <- str_to_title(camera_address$SUBURB)
#Concatenate the two fields into a single address field
camera_address$ADDRESS <- paste(camera_address$LOCATION,
camera_address$SUBURB,
sep=", ")
#Add in Australia to the address field just to idiot proof the df
camera_address$ADDRESS <- paste(camera_address$ADDRESS, ", Australia", sep="")
#Preview the data
head(camera_address)
#Input the google API key
register_google(key = "PASTE YOUR UNIQUE KEY HERE")
#Run the geocode function from ggmap package
camera_ggmap <- ggmap::geocode(location = camera_address$ADDRESS,
output = "more",
source = "google")
#We'll bind the newly created address columns to the original df
camera_ggmap <- cbind(camera_address, camera_ggmap)
#Print the results
head(camera_ggmap)
#Loads the required required packages
pacman::p_load(ggmap,
tmaptools,
RCurl,
jsonlite,
tidyverse,
leaflet,
writexl,
readr,
readxl,
sf,
mapview,
rgdal)
#Read in spreadsheet
url <- 'https://raw.githubusercontent.com/charlescoverdale/bookdata/main/mobile-camera-locations-june-2022.csv'
#Note: We need to import as a csv rather than xlsx for url functionality
camera_address <- read.csv(url, header=TRUE)
#Fix the column labels
camera_address <- janitor::row_to_names(camera_address,1)
#Convert the suburb column to title case
camera_address$SUBURB <- str_to_title(camera_address$SUBURB)
#Concatenate the two fields into a single address field
camera_address$ADDRESS <- paste(camera_address$LOCATION,
camera_address$SUBURB,
sep=", ")
#Add in Australia to the address field just to idiot proof the df
camera_address$ADDRESS <- paste(camera_address$ADDRESS, ", Australia", sep="")
#Preview the data
head(camera_address)
url <- 'https://raw.githubusercontent.com/charlescoverdale/bookdata/main/camera_geocoded.csv'
#Note: We need to import as a csv rather than xlsx for url functionality
camera_ggmap <- read.csv(url, header=TRUE)
camera_geocoded <- camera_ggmap
#Rename df
camera_geocoded_clean <- camera_geocoded
#Rename the API generated address field
camera_geocoded_clean <- camera_geocoded_clean %>% rename(address_long=address)
#Select only the columns we need
camera_geocoded_clean <- camera_geocoded_clean %>%
select("LOCATION",
"SUBURB",
"ADDRESS",
"lon",
"lat",
"address_long"
)
#Make all the column names the same format
camera_geocoded_clean <- janitor::clean_names(camera_geocoded_clean)
#We still need to convert address_long to title case
camera_geocoded_clean$address_long <- str_to_title(camera_geocoded_clean$address_long)
#Convert data frame to sf object
camera_points <- sf::st_as_sf(x = camera_geocoded_clean,
coords = c("lon", "lat"),
crs = "+proj=longlat
+datum=WGS84
+ellps=WGS84
+towgs84=0,0,0")
#Plot an interactive map
# mapview(camera_points)
camera_points$postcode <- str_sub(camera_points$address_long,
start= -16,
end= -12)
camera_points$postcode <- as.numeric(camera_points$postcode)
outliers <- camera_points %>% filter (postcode <3000 | postcode >= 4000)
print(outliers)
camera_points_vic <- camera_points %>% filter (postcode>"3000" & postcode<"4000")
#Plot an interactive map
# mapview(camera_points_vic)
camera_points_vic <- camera_points %>% filter (postcode>"3000" & postcode<"4000")
head(camera_points_vic)
#Plot an interactive map
# mapview(camera_points_vic)
# Create a dataframe with the latitude and longitude
locations <- tibble::tribble(
~place,     ~lon,     ~lat,
"Melbourne", 144.9631, -37.8136
)
# Run it through the osrm package to calculate isochrones
iso <- osrmIsochrone(
loc = c(locations$lon, locations$lat),
breaks = seq(from = 0, to = 30, by = 5),
res = 50
)
#Loads the required required packages
pacman::p_load(ggmap, tmaptools, RCurl, jsonlite, tidyverse, leaflet, writexl, readr, readxl, sf, mapview, rgdal, osrm)
# Create a dataframe with the latitude and longitude
locations <- tibble::tribble(
~place,     ~lon,     ~lat,
"Melbourne", 144.9631, -37.8136
)
# Run it through the osrm package to calculate isochrones
iso <- osrmIsochrone(
loc = c(locations$lon, locations$lat),
breaks = seq(from = 0, to = 30, by = 5),
res = 50
)
# Create an interactive map
# leaflet() %>%
#   setView(mean(locations$lon), mean(locations$lat), zoom = 7) %>%
#   addProviderTiles("CartoDB.Positron", group = "Greyscale") %>%
#   addMarkers(lng = locations$lon, lat = locations$lat) %>%
#   addPolygons(
#     fill = TRUE, stroke = TRUE, color = "black",
#     weight = 0.5, fillOpacity = 0.2,
#     data = iso,
#     group = "Drive Time"
#   )
