head(camera_points_vic)
#Plot an interactive map
# mapview(camera_points_vic)
# Create a dataframe with the latitude and longitude
locations <- tibble::tribble(
~place,     ~lon,     ~lat,
"Melbourne", 144.9631, -37.8136
)
# Run it through the osrm package to calculate isochrones
iso <- osrmIsochrone(
loc = c(locations$lon, locations$lat),
breaks = seq(from = 0, to = 30, by = 5),
res = 50
)
#Loads the required required packages
pacman::p_load(ggmap, tmaptools, RCurl, jsonlite, tidyverse, leaflet, writexl, readr, readxl, sf, mapview, rgdal, osrm)
# Create a dataframe with the latitude and longitude
locations <- tibble::tribble(
~place,     ~lon,     ~lat,
"Melbourne", 144.9631, -37.8136
)
# Run it through the osrm package to calculate isochrones
iso <- osrmIsochrone(
loc = c(locations$lon, locations$lat),
breaks = seq(from = 0, to = 30, by = 5),
res = 50
)
# Create an interactive map
# leaflet() %>%
#   setView(mean(locations$lon), mean(locations$lat), zoom = 7) %>%
#   addProviderTiles("CartoDB.Positron", group = "Greyscale") %>%
#   addMarkers(lng = locations$lon, lat = locations$lat) %>%
#   addPolygons(
#     fill = TRUE, stroke = TRUE, color = "black",
#     weight = 0.5, fillOpacity = 0.2,
#     data = iso,
#     group = "Drive Time"
#   )
install.packages("cli", dependencies = TRUE, type = "source")
# Load in required packages
library(tidyverse)   # Includes ggplot2, dplyr, purrr, stringr, etc.
library(ggridges)    # For ridge plots
library(forecast)    # Time series forecasting
library(ggrepel)     # For better text label placement
library(viridis)     # Color scales
library(readxl)      # Excel file reading
library(lubridate)   # Date and time manipulation
library(gapminder)   # Gapminder data for examples
library(ggalt)       # Additional ggplot2 geoms
library(scales)      # Scale functions for ggplot2
econ_data <- economics %>% dplyr::select(c("date", "uempmed"))
econ_data <- econ_data %>% dplyr::filter((date >= as.Date("1970-01-01")
& date <= as.Date("1999-12-31")))
aus_unemp_rate <- read_rba(series_id = "GLFSURSA")
# Load in required packages
library(tidyverse)   # Includes ggplot2, dplyr, purrr, stringr, etc.
library(ggridges)    # For ridge plots
library(forecast)    # Time series forecasting
library(ggrepel)     # For better text label placement
library(viridis)     # Color scales
library(readxl)      # Excel file reading
library(lubridate)   # Date and time manipulation
library(gapminder)   # Gapminder data for examples
library(ggalt)       # Additional ggplot2 geoms
library(scales)      # Scale functions for ggplot2
library(readrba)
aus_unemp_rate <- readrba::read_rba(series_id = "GLFSURSA")
head(aus_unemp_rate)
ggplot(econ_data) +
geom_point(aes(x = date, y = uempmed), col = "grey", alpha = 0.5) +
geom_smooth(aes(x = date, y = uempmed), col = "blue") +
labs(title = "Unemployment rate",
caption = "Data: ggplot2::economics",
x = "",
y = "") +
theme_minimal() +
theme(
plot.title = element_text(face = "bold", size = 12, margin = margin(0, 0, 25, 0)),
plot.subtitle = element_text(size = 11),
plot.caption = element_text(size = 8),
axis.text = element_text(size = 8),
axis.title.y = element_text(margin = margin(t = 0, r = 3, b = 0, l = 0)),
axis.text.y = element_text(vjust = -0.5, margin = margin(l = 20, r = -10)),
axis.line.x = element_line(colour = "black", size = 0.4),
axis.ticks.x = element_line(colour = "black", size = 0.4),
panel.grid.minor = element_blank(),
panel.grid.major.x = element_blank(),
legend.position = "bottom"
)
# Test for stationarity
aTSA::adf.test(econ_data$uempmed)
# See the auto correlation
acf(econ_data$uempmed)
# Identify partial auto correlation
pacf(econ_data$uempmed)
# Take the first differences of the series
econ_data <- econ_data %>% mutate(diff = uempmed - lag(uempmed))
# Plot the first differences
ggplot(econ_data, aes(x = date, y = diff)) +
geom_point(col = "grey", alpha = 0.5) +
geom_smooth(col = "blue") +
labs(
title = "1st Difference (Unemployment Rate)",
caption = "Data: ggplot2::economics",
x = "",
y = ""
) +
theme_minimal() +
theme(
legend.position = "bottom",
plot.title = element_text(face = "bold", size = 12, margin = margin(0, 0, 25, 0)),
plot.subtitle = element_text(size = 11),
plot.caption = element_text(size = 8),
axis.text = element_text(size = 8),
axis.title.y = element_text(margin = margin(t = 0, r = 3, b = 0, l = 0)),
axis.text.y = element_text(vjust = -0.5, margin = margin(l = 20, r = -10)),
axis.line.x = element_line(colour = "black", size = 0.4),
axis.ticks.x = element_line(colour = "black", size = 0.4),
panel.grid.minor = element_blank(),
panel.grid.major.x = element_blank()
)
# Fit an ARIMA model
ARIMA_model <- forecast::auto.arima(econ_data$uempmed)
# Display model summary and residual diagnostics
summary(ARIMA_model)
forecast::checkresiduals(ARIMA_model)
# Forecast for the next 36 time periods
ARIMA_forecast <- forecast::forecast(ARIMA_model, h = 36, level = c(95))
# Plot the forecast
plot(ARIMA_forecast)
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
ggplot2, caret, skimr, RANN, randomForest, fastAdaboost, gbm, xgboost,
caretEnsemble, C50, caTools
)
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
ggplot2, caret, skimr, RANN, randomForest, gbm, xgboost,
caretEnsemble, C50, caTools
)
# Let's use the mtcars dataset as an example
# Fit a model to the mtcars data
data(mtcars)
# Build a linear model to explain mpg using hp
mtcars_model <- lm(mpg ~ hp, mtcars)
# Run the model over the data
mtcars_model_estimates <- predict(mtcars_model,mtcars)
# Bind the original figures for mpg with the predicted figures for mpg
mtcars_model_outputs <- cbind(Actual_mpg=mtcars$mpg,
Actual_hp=mtcars$hp,
Predicted_mpg=mtcars_model_estimates,
Residuals=resid(mtcars_model),
Fitted=fitted(mtcars_model))
# Ensure the outputs are a df
mtcars_model_outputs <- as.data.frame(mtcars_model_outputs)
ggplot(mtcars_model_outputs) +
geom_line(aes(x = Actual_hp, y = Predicted_mpg), color = "blue") +
geom_point(aes(x = Actual_hp, y = Actual_mpg), color = "blue", alpha = 0.5) +
geom_segment(aes(x = Actual_hp, y = Actual_mpg, xend = Actual_hp, yend = Fitted),
color = "black", alpha = 0.8, linetype = "dotted") +
labs(
title = "Building a Regression Model",
subtitle = "Higher horsepower cars get fewer miles per gallon",
caption = "Data: mtcars dataset",
x = "Horsepower",
y = "Miles per Gallon"
) +
theme_minimal() +
theme(
legend.position = "bottom",
plot.title = element_text(face = "bold", size = 12),
plot.subtitle = element_text(size = 11, margin = margin(b = 25)),
plot.caption = element_text(size = 8),
axis.text = element_text(size = 8),
axis.title.y = element_text(margin = margin(r = 3)),
axis.text.y = element_text(margin = margin(l = 10)),
axis.line.x = element_line(color = "black", size = 0.4),
axis.ticks.x = element_line(color = "black", size = 0.4),
panel.grid.minor = element_blank()
)
ggplot(mtcars_model_outputs) +
geom_line(aes(x = Actual_hp, y = Predicted_mpg), color = "blue") +
geom_point(aes(x = Actual_hp, y = Actual_mpg), color = "blue", alpha = 0.5) +
geom_segment(aes(x = Actual_hp, y = Actual_mpg, xend = Actual_hp, yend = Fitted),
color = "black", alpha = 0.8, linetype = "dotted") +
labs(
title = "Building a Regression Model",
subtitle = "Higher horsepower cars get fewer miles per gallon",
caption = "Data: mtcars dataset",
x = "Horsepower",
y = "Miles per Gallon"
) +
theme_minimal() +
theme(
legend.position = "bottom",
plot.title = element_text(face = "bold", size = 12),
plot.subtitle = element_text(size = 11, margin = margin(b = 25)),
plot.caption = element_text(size = 8),
axis.text = element_text(size = 8),
axis.title.y = element_text(margin = margin(r = 3)),
axis.text.y = element_text(margin = margin(l = 10)),
axis.line.x = element_line(color = "black", size = 0.4),
axis.ticks.x = element_line(color = "black", size = 0.4),
panel.grid.minor = element_blank()
)
ggplot(mtcars_model_outputs) +
geom_line(aes(x = Actual_hp, y = Predicted_mpg), color = "blue") +
geom_point(aes(x = Actual_hp, y = Actual_mpg), color = "blue", alpha = 0.5) +
geom_segment(aes(x = Actual_hp, y = Actual_mpg, xend = Actual_hp, yend = Fitted),
color = "black", alpha = 0.8, linetype = "dotted") +
labs(
title = "Building a Regression Model",
subtitle = "Higher horsepower cars get fewer miles per gallon",
caption = "Data: mtcars dataset",
x = "Horsepower",
y = "Miles per Gallon"
) +
theme_minimal() +
theme(
legend.position = "bottom",
plot.title = element_text(face = "bold", size = 12),
plot.subtitle = element_text(size = 11, margin = ggplot2::margin(b = 25)),
plot.caption = element_text(size = 8),
axis.text = element_text(size = 8),
axis.title.y = element_text(margin = ggplot2::margin(r = 3)),
axis.text.y = element_text(margin = ggplot2::margin(l = 10)),
axis.line.x = element_line(color = "black", size = 0.4),
axis.ticks.x = element_line(color = "black", size = 0.4),
panel.grid.minor = element_blank()
)
# Manually calculate RMSE
error <- mtcars_model_outputs$Actual_mpg - mtcars_model_outputs$Fitted
mtcars_rmse_manual <- sqrt(mean(error^2))
# Alternative: Using Residuals column directly
mtcars_rmse_residuals <- sqrt(mean(mtcars_model_outputs$Residuals^2))
# Print results
print(mtcars_rmse_manual)
print(mtcars_rmse_residuals)
# Load necessary libraries
library(MASS)
library(caret)
# Load the Boston housing dataset
data("Boston")
# Splitting the dataset into training (80%) and testing (20%) sets
set.seed(123)
train_index <- createDataPartition(Boston$medv, p=0.8, list=FALSE)
train_data <- Boston[train_index, ]
test_data <- Boston[-train_index, ]
# Display the first few rows of each dataset to confirm the split
head(train_data)
head(test_data)
# Load necessary library
library(randomForest)
# Train a Random Forest model with 100 trees
model <- randomForest(medv ~ ., data=train_data, ntree=100)
# Make predictions on the test set
predictions <- predict(model, test_data)
# Calculate RMSE
rmse <- sqrt(mean((predictions - test_data$medv)^2))
# Print RMSE result
print(paste("RMSE:", round(rmse, 2)))
# Load necessary library
library(tidymodels)
# Set a seed for reproducibility
set.seed(123)
# Define a linear regression model
ml_model <- linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
# Create a workflow that includes the model and the formula
tidymodels_workflow <- workflow() %>%
add_model(ml_model) %>%
add_formula(medv ~ .)
# Train the linear regression model
trained_model <- tidymodels_workflow %>% fit(data = train_data)
# Make predictions using the trained model
predictions <- predict(trained_model, test_data) %>% bind_cols(test_data)
# Evaluate model performance using metrics function
metrics(predictions, truth = medv, estimate = .pred)
# Load necessary library
library(tidymodels)
# Set a seed for reproducibility
set.seed(123)
# Define a linear regression model
ml_model <- linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
# Create a workflow that includes the model and the formula
tidymodels_workflow <- workflow() %>%
add_model(ml_model) %>%
add_formula(medv ~ .)
# Train the linear regression model
trained_model <- tidymodels_workflow %>% fit(data = train_data)
# Train a Random Forest model with 100 trees
model <- randomForest::randomForest(medv ~ ., data=train_data, ntree=100)
# Make predictions on the test set
predictions <- predict(model, test_data)
# Calculate RMSE
rmse <- sqrt(mean((predictions - test_data$medv)^2))
# Print RMSE result
print(paste("RMSE:", round(rmse, 2)))
remove.packages("randomForest")
"randomForest" %in% rownames(installed.packages())
xcode-select --install
install.packages("randomForest")
install.packages("randomForest")
# Test for stationarity
aTSA::adf.test(econ_data$uempmed)
# See the auto correlation
acf(econ_data$uempmed)
# Identify partial auto correlation
pacf(econ_data$uempmed)
# Take the first differences of the series
econ_data <- econ_data %>% mutate(diff = uempmed - lag(uempmed))
# Plot the first differences
ggplot(econ_data, aes(x = date, y = diff)) +
geom_point(col = "grey", alpha = 0.5) +
geom_smooth(col = "blue") +
labs(
title = "1st Difference (Unemployment Rate)",
caption = "Data: ggplot2::economics",
x = "",
y = ""
) +
theme_minimal() +
theme(
legend.position = "bottom",
plot.title = element_text(face = "bold", size = 12, margin = ggplot2::margin(0, 0, 25, 0)),
plot.subtitle = element_text(size = 11),
plot.caption = element_text(size = 8),
axis.text = element_text(size = 8),
axis.title.y = element_text(margin = ggplot2::margin(t = 0, r = 3, b = 0, l = 0)),
axis.text.y = element_text(vjust = -0.5, margin = ggplot2::margin(l = 20, r = -10)),
axis.line.x = element_line(colour = "black", size = 0.4),
axis.ticks.x = element_line(colour = "black", size = 0.4),
panel.grid.minor = element_blank(),
panel.grid.major.x = element_blank()
)
ggplot(econ_data) +
geom_point(aes(x = date, y = uempmed), col = "grey", alpha = 0.5) +
geom_smooth(aes(x = date, y = uempmed), col = "blue") +
labs(title = "Unemployment rate",
caption = "Data: ggplot2::economics",
x = "",
y = "") +
theme_minimal() +
theme(
plot.title = element_text(face = "bold", size = 12, margin = ggplot2::margin(0, 0, 25, 0)),
plot.subtitle = element_text(size = 11),
plot.caption = element_text(size = 8),
axis.text = element_text(size = 8),
axis.title.y = element_text(margin = ggplot2::margin(t = 0, r = 3, b = 0, l = 0)),
axis.text.y = element_text(vjust = -0.5, margin = ggplot2::margin(l = 20, r = -10)),
axis.line.x = element_line(colour = "black", size = 0.4),
axis.ticks.x = element_line(colour = "black",
ggplot(econ_data) +
geom_point(aes(x = date, y = uempmed), col = "grey", alpha = 0.5) +
geom_smooth(aes(x = date, y = uempmed), col = "blue") +
labs(title = "Unemployment rate",
caption = "Data: ggplot2::economics",
x = "",
y = "") +
theme_minimal() +
theme(
plot.title = element_text(face = "bold", size = 12, margin = ggplot2::margin(0, 0, 25, 0)),
plot.subtitle = element_text(size = 11),
plot.caption = element_text(size = 8),
axis.text = element_text(size = 8),
axis.title.y = element_text(margin = ggplot2::margin(t = 0, r = 3, b = 0, l = 0)),
axis.text.y = element_text(vjust = -0.5, margin = ggplot2::margin(l = 20, r = -10)),
axis.line.x = element_line(colour = "black", size = 0.4),
axis.ticks.x = element_line(colour = "black", size = 0.4),
panel.grid.minor = element_blank(),
panel.grid.major.x = element_blank(),
legend.position = "bottom"
)
# Train a Random Forest model with 100 trees
model <- randomForest::randomForest(medv ~ ., data=train_data, ntree=100)
# Make predictions on the test set
predictions <- predict(model, test_data)
# Manually calculate RMSE
error <- mtcars_model_outputs$Actual_mpg - mtcars_model_outputs$Fitted
mtcars_rmse_manual <- sqrt(mean(error^2))
# Alternative: Using Residuals column directly
mtcars_rmse_residuals <- sqrt(mean(mtcars_model_outputs$Residuals^2))
# Print results
print(mtcars_rmse_manual)
print(mtcars_rmse_residuals)
# Load necessary libraries
library(MASS)
library(caret)
# Load the Boston housing dataset
data("Boston")
# Splitting the dataset into training (80%) and testing (20%) sets
set.seed(123)
train_index <- createDataPartition(Boston$medv, p=0.8, list=FALSE)
train_data <- Boston[train_index, ]
test_data <- Boston[-train_index, ]
# Display the first few rows of each dataset to confirm the split
head(train_data)
head(test_data)
# Train a Random Forest model with 100 trees
model <- randomForest::randomForest(medv ~ ., data=train_data, ntree=100)
# Make predictions on the test set
predictions <- predict(model, test_data)
# Calculate RMSE
rmse <- sqrt(mean((predictions - test_data$medv)^2))
# Print RMSE result
print(paste("RMSE:", round(rmse, 2)))
# Load necessary library
library(tidymodels)
# Set a seed for reproducibility
set.seed(123)
# Define a linear regression model
ml_model <- linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
# Create a workflow that includes the model and the formula
tidymodels_workflow <- workflow() %>%
add_model(ml_model) %>%
add_formula(medv ~ .)
# Train the linear regression model
trained_model <- tidymodels_workflow %>% fit(data = train_data)
# Make predictions using the trained model
predictions <- predict(trained_model, test_data) %>% bind_cols(test_data)
# Evaluate model performance using metrics function
metrics(predictions, truth = medv, estimate = .pred)
#Loads the required required packages
pacman::p_load(ggmap,
tmaptools,
RCurl,
jsonlite,
tidyverse,
leaflet,
writexl,
readr,
readxl,
sf,
mapview,
rgdal)
#Read in spreadsheet
url <- 'https://raw.githubusercontent.com/charlescoverdale/bookdata/main/mobile-camera-locations-june-2022.csv'
#Note: We need to import as a csv rather than xlsx for url functionality
camera_address <- read.csv(url, header=TRUE)
#Fix the column labels
camera_address <- janitor::row_to_names(camera_address,1)
#Convert the suburb column to title case
camera_address$SUBURB <- str_to_title(camera_address$SUBURB)
#Concatenate the two fields into a single address field
camera_address$ADDRESS <- paste(camera_address$LOCATION,
camera_address$SUBURB,
sep=", ")
#Add in Australia to the address field just to idiot proof the df
camera_address$ADDRESS <- paste(camera_address$ADDRESS, ", Australia", sep="")
#Preview the data
head(camera_address)
url <- 'https://raw.githubusercontent.com/charlescoverdale/bookdata/main/camera_geocoded.csv'
#Note: We need to import as a csv rather than xlsx for url functionality
camera_ggmap <- read.csv(url, header=TRUE)
camera_geocoded <- camera_ggmap
#Rename df
camera_geocoded_clean <- camera_geocoded
#Rename the API generated address field
camera_geocoded_clean <- camera_geocoded_clean %>% rename(address_long=address)
#Select only the columns we need
camera_geocoded_clean <- camera_geocoded_clean %>%
select("LOCATION",
"SUBURB",
"ADDRESS",
"lon",
"lat",
"address_long"
)
#Rename df
camera_geocoded_clean <- camera_geocoded
#Rename the API generated address field
camera_geocoded_clean <- camera_geocoded_clean %>% rename(address_long=address)
#Select only the columns we need
camera_geocoded_clean <- camera_geocoded_clean %>%
dplyr::select("LOCATION",
"SUBURB",
"ADDRESS",
"lon",
"lat",
"address_long"
)
#Make all the column names the same format
camera_geocoded_clean <- janitor::clean_names(camera_geocoded_clean)
#We still need to convert address_long to title case
camera_geocoded_clean$address_long <- str_to_title(camera_geocoded_clean$address_long)
#Convert data frame to sf object
camera_points <- sf::st_as_sf(x = camera_geocoded_clean,
coords = c("lon", "lat"),
crs = "+proj=longlat
+datum=WGS84
+ellps=WGS84
+towgs84=0,0,0")
#Plot an interactive map
# mapview(camera_points)
camera_points$postcode <- str_sub(camera_points$address_long,
start= -16,
end= -12)
camera_points$postcode <- as.numeric(camera_points$postcode)
outliers <- camera_points %>% filter (postcode <3000 | postcode >= 4000)
print(outliers)
pkg_name_check(uktools, dictionaries = NULL)
install.packages("pok")
library(pak)
install.packages("pak")
library(pak)
pkg_name_check(uktools, dictionaries = NULL)
pkg_name_check(econtools, dictionaries = NULL)
