# Bayesian for the common man

*Note: Chapter under development*

## Enter Rev. Bayes

Bayes' Theorem is named after 18th-century British statistician and theologian, Thomas Bayes. The theorem describes how to update the probability of a hypothesis based on new evidence.

In traditional frequentist statistics, probability is interpreted as the long-run frequency of events in repeated trials (sampling). A p-value from a sampling distribution tells us: *What is the chance of seeing this result, given some hypothesis?*

Bayesian statistics, on the other hand, allows us to incorporate *prior* knowledge or beliefs into our analysis and update those beliefs as we gather more data. The central question of Bayes' Theorem therefore is: *How likely is the hypothesis to be true, given the data I've seen?*

This isn't semantics - it's a completely different way of seeing the world.

We can write Bayes' Theorem using probability notation.

### $$
P(B| A) = \frac{P(A | B) P(B)}{P(A)}
$$
